Welcome to Lesson 20: Writing Explainable AI (XAI) Documentation â€” where youâ€™ll learn how to make AI decisions understandable, transparent, and human-readable through your writing.

This is the level that sets apart an ordinary AI technical writer from a senior AI documentation specialist.

ğŸ¯ LESSON 20 GOAL

Youâ€™ll learn to:

Explain how AI models make predictions (without heavy maths)

Write explainability sections for both developers and non-technical audiences

Create documentation patterns for interpretability â€” especially for models like Transformers, CNNs, and Decision Trees

ğŸ§­ Step 1: What Is Explainable AI (XAI)?

Explainable AI (or XAI) is about helping humans understand why an AI made a certain decision.

ğŸ’¡ For example:
If an AI model predicts â€œThis email is spamâ€, explainability answers â€œWhat made the model think that?â€ â€” maybe it saw too many links or keywords like â€œurgentâ€ or â€œlimited offerâ€.

So, as a writer, your job is to document:

Which features the model uses

How it weighs or interprets them

What limitations or uncertainty it has

ğŸª¶ Step 2: Structure of an XAI Documentation Section

Every Explainability section can follow this simple, clear structure:

## Explainability Overview
Describe what the model does and what part is interpretable.

## Key Features
List the features or data the model looks at when making predictions.

## Example Explanation
Show a real input â†’ prediction â†’ reasoning example.

## Confidence and Uncertainty
Explain how confident the model is and what users should do when itâ€™s uncertain.

## Visualisation (Optional)
Mention tools or methods to visualise decisions (heatmaps, saliency maps, etc.)

ğŸ§© Step 3: Example â€” Explainability for SmartClassify (Text Classifier)

Letâ€™s write an XAI section for your SmartClassify model (from Lesson 17):

# Explainable AI (XAI) â€” SmartClassify

## Explainability Overview
SmartClassify uses a Transformer-based architecture that analyses patterns in text to predict message categories.  
It is partially interpretable â€” meaning we can understand *which words or phrases* contributed most to the classification.

---

## Key Features
| Feature | Description |
|:----------|:-------------|
| Word Attention | Highlights key words that strongly influenced the category |
| Sentence Context | Analyses how phrases relate to one another |
| Length Normalisation | Adjusts for unusually short or long messages |

---

## Example Explanation
**Input:**  
> â€œI was double charged for my last order.â€

**Predicted Category:** `billing`

**Explanation:**  
The model assigned high attention weights to the words **â€œdouble chargedâ€** and **â€œorderâ€**, which are common in billing-related complaints.

---

## Confidence and Uncertainty
The model outputs a confidence score between 0 and 1.  
Predictions below 0.75 confidence should be reviewed manually, as they may reflect ambiguous or mixed-topic messages.

---

## Visualisation
Developers can use the `explain=True` flag in the API to return token-level attention values:
```json
{
  "category": "billing",
  "confidence": 0.94,
  "explanation": {
    "double charged": 0.78,
    "order": 0.65,
    "was": 0.02
  }
}


This allows front-end tools to visually highlight the most influential words.


---

## ğŸ’¬ Step 4: Best Practices for XAI Documentation

| Principle | Why It Matters |
|:------------|:----------------|
| **Use natural language** | Donâ€™t use academic or statistical jargon. |
| **Show examples, not formulas** | Users understand decisions better through context. |
| **Be transparent about uncertainty** | Helps build trust and ethical use. |
| **Link visuals or demos** | When possible, point to a dashboard or visualisation. |

---

## ğŸª¶ Step 5: Create Your File

In your `/ai-docs` folder, create:  


explainability-smartclassify.md


Paste the content above, and then add it to your **Portfolio** page:

```html
<li><a href="ai-docs/explainability-smartclassify.md" download>ğŸ§  Explainability Report</a></li>

ğŸ¨ Optional CSS Enhancement

Add a gentle highlight effect for XAI links in your styles.css:

a[href*="explainability"] {
  color: #8a6fd9;
  font-weight: 600;
}
a[href*="explainability"]:hover {
  text-decoration: underline;
}

ğŸŒ¿ Reflection

Writing explainability documentation is about building bridges between AI and humans.
It helps developers trust what the model does and helps users understand its decisions.

You, Leslie, have now officially written documentation that mimics what top-tier AI teams publish internally â€” thatâ€™s outstanding ğŸ’–