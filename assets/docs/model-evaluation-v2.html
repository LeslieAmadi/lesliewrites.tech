<!DOCTYPE html>
<html lang="en-GB">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Model Evaluation Report Multilingual Chatbot v2.0 | Leslie Writes</title>
  <link rel="stylesheet" href="../styles.css">

  
</head>

<body>
<div class="docs-body">

<header>
  <h1>Model Evaluation Report: Multilingual Chatbot Model v2.0</h1>
    <nav class="docs-toc docs-toc-dropdown">
      <details open>
        <summary>On this page</summary>
        <ol>
          <li><a href="#1-objective">1. Objective</a></li>
          <li><a href="#2-evaluation-datasets">2. Evaluation Datasets</a></li>
          <li><a href="#3-evaluation-metrics">3. Evaluation Metrics</a></li>
          <li><a href="#4-results-summary">4. Results Summary</a></li>
          <li><a href="#5-error-analysis">5. Error Analysis</a></li>
          <li><a href="#6-interpretation-insights">6. Interpretation &amp; Insights</a></li>
          <li><a href="#7-visual-summary">7. Visual Summary</a></li>
          <li><a href="#8-recommendations">8. Recommendations</a></li>
          <li><a href="#9-deployment-readiness">9. Deployment Readiness</a></li>
          <li><a href="#10-document-metadata">10. Document Metadata</a></li>
        </ol>
      </details>
    </nav>
    <section class="doc-meta-grid">
      <h2 class="doc-meta-title">Role &amp; Outcomes</h2>
      <div class="doc-meta-row">
        <div class="doc-meta-item">
          <h3>Overview</h3>
          <p>This document describes <strong>Model Evaluation Report Multilingual Chatbot v2.0 | Leslie Writes</strong> and is written from the perspective of a technical writer supporting engineers, product, and operations.</p>
        </div>
        <div class="doc-meta-item">
          <h3>My Role</h3>
          <p>Planned the structure, authored the documentation, and aligned the content with stakeholders so it can be used as a repeatable reference and onboarding asset.</p>
        </div>
      </div>
      <div class="doc-meta-row">
        <div class="doc-meta-item">
          <h3>Audience</h3>
          <p>Primarily software engineers, data/ML practitioners, and product or operations teams who need a clear view of behaviour, integration steps, and edge cases.</p>
        </div>
        <div class="doc-meta-item">
          <h3>Scope</h3>
          <p>In scope: product behaviour, configuration, integration flows, and operational considerations. Out of scope: commercial terms, team processes, and non-technical marketing copy.</p>
        </div>
      </div>
      <div class="doc-meta-row">
        <div class="doc-meta-item">
          <h3>Prerequisites</h3>
          <p>Comfortable reading technical documentation and basic familiarity with the surrounding stack (e.g. APIs, data pipelines, dashboards, or game engines, depending on context).</p>
        </div>
        <div class="doc-meta-item">
          <h3>Impact</h3>
          <p>Intended to reduce back-and-forth clarification, speed up onboarding, and make future changes safer by giving teams a single, well-structured source of truth.</p>
        </div>
      </div>
    </section>


  <p><em>Prepared by Leslie Amadi — Senior AI Technical Writer</em></p>
  <hr>
</header>

<div class="docs-content">

<!-- SECTION 1 -->
<h2 id="1-objective">1. Objective</h2>
<p>
  This report evaluates the performance of the <strong>Multilingual Chatbot Model v2.0</strong>,
  designed for English–German customer service applications. The primary objective is to compare
  v2.0 against the baseline <strong>v1.3</strong> across accuracy, conversational fluency, intent recognition,
  model reliability, and multilingual robustness.
</p>

<div class="callout">
  <strong>Scope:</strong> This report covers offline evaluation, dataset-level testing, error analysis,
  and deployment readiness. Live production testing is scheduled for the next release cycle.
</div>

<!-- SECTION 2 -->
<h2 id="2-evaluation-datasets">2. Evaluation Datasets</h2>
<p>
  Three datasets were selected to reflect real-world customer interactions, mixed-language usage,
  and varying levels of conversational complexity.
</p>

<h3>2.1 Dataset Summary</h3>
<table>
  <thead>
    <tr>
      <th>Dataset</th><th>Language</th><th>Size</th><th>Purpose</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Customer Support Eval Set</td>
      <td>English</td>
      <td>5,000 pairs</td>
      <td>Intent recognition + troubleshooting</td>
    </tr>
    <tr>
      <td>Kundenhilfe Eval Set</td>
      <td>German</td>
      <td>2,500 pairs</td>
      <td>Multilingual behavioural accuracy</td>
    </tr>
    <tr>
      <td>General QA Eval</td>
      <td>Mixed (EN/DE)</td>
      <td>3,000 pairs</td>
      <td>Fluency, coherence, correctness</td>
    </tr>
  </tbody>
</table>

<h3>2.2 Dataset Split</h3>
<ul>
  <li>Training: 80%</li>
  <li>Validation: 10%</li>
  <li>Testing: 10% (7,500 samples)</li>
</ul>

<h3>2.3 Data Characteristics</h3>
<ul>
  <li>Includes idioms, colloquial expressions, and fragmented queries.</li>
  <li>Reflects typical European customer service patterns.</li>
  <li>Balanced domain coverage: billing, delivery, returns, technical issues.</li>
</ul>

<!-- SECTION 3 -->
<h2 id="3-evaluation-metrics">3. Evaluation Metrics</h2>
<p>
  The model was tested using industry-standard evaluation metrics for classification and
  conversational agents. Definitions are provided below for clarity.
</p>

<table>
  <thead>
    <tr>
      <th>Metric</th><th>Definition</th><th>Target</th><th>Achieved</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Accuracy</td>
      <td>(Correct predictions ÷ total predictions)</td>
      <td>90%</td>
      <td><strong>91.5%</strong></td>
    </tr>
    <tr>
      <td>Precision</td>
      <td>TP ÷ (TP + FP)</td>
      <td>85%</td>
      <td><strong>88%</strong></td>
    </tr>
    <tr>
      <td>Recall</td>
      <td>TP ÷ (TP + FN)</td>
      <td>80%</td>
      <td><strong>84%</strong></td>
    </tr>
    <tr>
      <td>F1 Score</td>
      <td>2 × (Precision × Recall) ÷ (Precision + Recall)</td>
      <td>82%</td>
      <td><strong>86%</strong></td>
    </tr>
  </tbody>
</table>

<!-- SECTION 4 -->
<h2 id="4-results-summary">4. Results Summary</h2>
<p>
  Overall performance improved significantly over the v1.3 baseline. The model demonstrates
  stronger multilingual intent recognition, reduced hallucinations, and improved handling of
  structured troubleshooting queries.
</p>

<h3>4.1 Accuracy by Language</h3>
<table>
  <thead>
    <tr>
      <th>Language</th><th>v1.3</th><th>v2.0</th><th>Difference</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>English</td>
      <td>89%</td>
      <td>93%</td>
      <td>+4%</td>
    </tr>
    <tr>
      <td>German</td>
      <td>84%</td>
      <td>90%</td>
      <td>+6%</td>
    </tr>
  </tbody>
</table>

<!-- SECTION 5 -->
<h2 id="5-error-analysis">5. Error Analysis</h2>

<h3>5.1 Frequent Error Types</h3>
<ul>
  <li><strong>Colloquial German misinterpretation</strong> — difficulty with slang and colloquial verbs.</li>
  <li><strong>Long tail product queries</strong> — underrepresented items lead to uncertainty.</li>
  <li><strong>Ambiguous intent</strong> — queries with multiple overlapping intents.</li>
  <li><strong>Overly confident phrasing</strong> — softened in v2.0 but not eliminated.</li>
</ul>

<h3>5.2 Example Errors</h3>
<pre>
User (DE): "Wie läuft das mit dem Zurückschicken eigentlich?"
Model v2.0: Provides general policy but misses edge-case exceptions.

User (EN): "My charger died again and I'm tired of this."
Model v2.0: Treats it as troubleshooting only, ignoring emotional context.
</pre>

<h3>5.3 Confusion Matrix Overview</h3>
<p>(Simplified)</p>
<pre>
               Predicted
              C1   C2   C3
Actual C1    842   27   14
Actual C2     33  691   21
Actual C3     19   24  801
</pre>

<!-- SECTION 6 -->
<h2 id="6-interpretation-insights">6. Interpretation & Insights</h2>
<ul>
  <li><strong>Improved domain generalisation:</strong> v2.0 handles new product categories better.</li>
  <li><strong>Tone consistency improved:</strong> Fewer abrupt or robotic responses.</li>
  <li><strong>German grammar improved notably:</strong> Declensions and article usage more accurate.</li>
  <li><strong>Significant hallucination reduction:</strong> −32% compared to v1.3.</li>
</ul>

<!-- SECTION 7 -->
<h2 id="7-visual-summary">7. Visual Summary</h2>
<pre>
MODEL PERFORMANCE OVER TIME
v1.0  ████████████ 82%
v1.3  █████████████████ 87%
v2.0  ███████████████████████ 91.5%
</pre>

<!-- SECTION 8 -->
<h2 id="8-recommendations">8. Recommendations</h2>
<ul>
  <li>Add datasets for <strong>German slang and informal expressions</strong>.</li>
  <li>Introduce <strong>Hungarian</strong> and <strong>Ukrainian</strong> low-resource evaluations.</li>
  <li>Deploy continuous human-in-the-loop review for misclassification patterns.</li>
  <li>Develop an automated regression suite for future model iterations.</li>
  <li>Run fairness testing across language groups.</li>
</ul>

<!-- SECTION 9 -->
<h2 id="9-deployment-readiness">9. Deployment Readiness</h2>
<p>The model meets the minimum thresholds for deployment to staging environments:</p>
<ul>
  <li>Accuracy > 90%</li>
  <li>F1 Score > 85%</li>
  <li>Hallucination rate < 5%</li>
  <li>No critical errors in high-risk domains</li>
</ul>

<!-- SECTION 10 -->
<h2 id="10-document-metadata">10. Document Metadata</h2>
<p><strong>Date:</strong> 7 November 2025<br>
   <strong>Author:</strong> Leslie Amadi<br>
   <strong>Version:</strong> 2.0
</p>

<p>
  <a href="../../portfolio.html" class="btn">← Back to Portfolio</a>
</p>

</div>

<footer class="footer">
  <p>© 2025 Leslie Amadi — All Rights Reserved.</p>
</footer>

</div>
</body>
</html>


