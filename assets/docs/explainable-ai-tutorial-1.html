<!DOCTYPE html>
<html lang="en-GB">
<head>
<meta charset="UTF-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1.0"/>
<title>Tutorial | Explainable AI Pipeline | Leslie Amadi</title>
<link rel="stylesheet" href="../styles.css">
</head>

<body>

<header class="navbar">
  <div class="navbar-inner">
    <div class="logo">Leslie Amadi</div>
    <nav class="nav-menu">
      <a href="../../index.html">Home</a>
      <a href="../../portfolio.html" class="active">Portfolio</a>
      <a href="../../blog.html">Blog</a>
      <a href="../../about.html">About</a>
      <a href="../../contact.html">Contact</a>
    </nav>
  </div>
</header>

<div class="tag-row">
  <span class="tag">Tutorial</span>
  <span class="tag">AI Learning</span>
  <span class="tag">Explainable AI</span>
  <span class="tag">Foundations</span>
</div>

<header class="doc-header">
  <h1>Building an Explainable AI Risk Pipeline</h1>
  <p class="doc-subtitle">
    A guided learning experience that shows how raw data becomes prediction,
    and how prediction becomes something humans can understand and trust.
  </p>
  <a href="#lesson-start" class="btn">Start Lesson</a>
</header>

<div class="breadcrumb-nav">
  <a href="../../portfolio.html" class="btn-secondary btn">← Back to Portfolio</a>
</div>

<main class="content-shell">

<nav class="inline-toc">
  <strong>On this page:</strong>
  <a href="#lesson-start">Goal</a> ·
  <a href="#step1">Input</a> ·
  <a href="#step2">Prediction</a> ·
  <a href="#step3">Explainability</a> ·
  <a href="#repeat">Repetition</a>
</nav>

<section id="lesson-start">
  <h2>The Goal</h2>
  <p>
    In this lesson, we will move a small set of raw values through a simple
    prediction pipeline. As we do this, we will observe how structure forms,
    how signals emerge, and how systems transform complexity into meaning.
  </p>
  <p>
    We are not learning theory here.  
    We are learning by watching the system behave.
  </p>
  <p>
    By the end of the lesson, you will have experienced how an AI system
    becomes understandable — not through explanation, but through interaction.
  </p>
</section>

<section id="step1">
  <h2>Step 1 — Creating Structured Input</h2>

  <p>
    We begin with raw values. At this point, they are just numbers —
    isolated, contextless, and meaningless on their own.
  </p>

  <pre>
age, bmi, blood_pressure
54, 29.4, 142
  </pre>

  <p>
    Notice what has already happened.
  </p>

  <p>
    By placing these values into a structure, we have created the first layer of meaning.
    This is the foundation of every intelligent system: turning chaos into form.
  </p>

  <p>
    Structure is not decoration it is interpretation.
  </p>
</section>

<section id="step2">
  <h2>Step 2 — Transforming Structure into Signal</h2>

  <p>
    Now we pass this structured input into the prediction function.
  </p>

  <pre>predict_risk()</pre>

  <p>
    After a brief moment, the system responds:
  </p>

  <pre>0.68</pre>

  <p>
    Many values have now become one signal.
  </p>

  <p>
    This is the core transformation:
    complexity becomes compression,
    data becomes direction,
    information becomes meaning.
  </p>

  <p>
    You are now looking at abstraction in action —
    not as theory, but as experience.
  </p>
</section>

<section id="step3">
  <h2>Step 3 — Making the System Understandable</h2>

  <p>
    A signal alone cannot be trusted.
    A number alone cannot guide action.
  </p>

  <p>
    We now ask the system to explain itself.
  </p>

  <pre>explain_prediction()</pre>

  <p>
    The system responds:
  </p>

  <pre>
BMI: 41%
Blood Pressure: 37%
Age: 22%
  </pre>

  <p>
    Notice the shift.
  </p>

  <p>
    The system is no longer silent.  
    The system is no longer opaque.  
    The system is no longer distant.
  </p>

  <p>
    The prediction becomes readable.  
    The system becomes interpretable.  
    The signal becomes a story.
  </p>

  <p>
    This is not transparency as a feature —
    it is trust as a design outcome.
  </p>
</section>

<section id="repeat">
  <h2>Repeat the Experience</h2>

  <p>
    Change one value in the input.
  </p>

  <p>
    Run the same steps again.
  </p>

  <p>
    Watch the number change.  
    Watch the explanation change.  
    Watch how structure responds to variation.
  </p>

  <p>
    This repetition builds intuition.
  </p>

  <p>
    With each repetition, the system becomes familiar.  
    With each repetition, your confidence grows.  
    With each repetition, understanding deepens.
  </p>

  <p>
    This is how learning stabilises —
    not through explanation,
    but through experience.
  </p>
</section>

</main>

</body>
</html>
